# -*- coding: utf-8 -*-
import scrapy
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import json
import logging
from configparser import ConfigParser
import os, pathlib
import sys
sys.path.append(r"/home/ubuntu/publication_monitor/pub_monitor/pub_monitor")
from items import PubMonitorItem
from fuzzywuzzy import fuzz
from scrapy_splash import SplashRequest

class SedarSpider(scrapy.Spider):
    name = 'sedar'
    allowed_domains = ['www.sedar.com']
    start_urls = ['https://www.sedar.com/new_docs/new_annual_reports_en.htm']
    custom_settings = {'ROBOTSTXT_OBEY': False}

    def parse(self, response):
        soup = BeautifulSoup(response.text, 'html.parser')
        print(soup)
        rows = soup.find_all('table')[1].find_all('tr', recursive=True)
        header = []
        for count, i in enumerate(rows):
            if (i.find('td', {'colspan':'5', 'valign':'TOP'})) is not None:
                header.append(count)
        header.append(len(rows)+1)
        df = pd.read_excel(r"/home/ubuntu/publication_monitor/pub_monitor/Book1.xlsx")
        companies = list(df['Company Name'])
          
        def start_requests(self):
            url = "http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&checkedCategory=category_ndbg_szsh#sseMain"
            yield SplashRequest(url, callback=self.parse)

        for count, i in enumerate(header[1:-1], start=1):
            for j in range(i+1, header[count+1]-1):
                company_name = rows[i].text.strip()
                date = rows[j].find_all('td', recursive=False)[1].text.strip()
                SedarSpider['publication_date'] = date  = datetime.strptime(date, "%b %d %Y")
                SedarSpider['doc_name'] = rows[j].find_all('td', recursive=False)[3].text.strip()
                SedarSpider['doc_link'] = f"https://www.sedar.com/GetFile.do?lang=EN{rows[j].find_all('td', recursive=False)[3].find('a').attrs['title']}"
                ratios = []
                for company in companies:
                    ratios.append(fuzz.ratio(company_name.lower(), company.lower()))
                print("***"+companies[ratios.index(max(ratios))], max(ratios))
                df_row = df[df['Company Name']==companies[ratios.index(max(ratios))]]
                if (max(ratios)>80):
                    SedarSpider['company_name'] = df_row['Company Name'].iloc[0]
                    SedarSpider['company_id'] = df_row['Company ID'].iloc[0]
                    SedarSpider['mkey'] = None
                    SedarSpider['trgr'] = df_row['TRIGGER_DOC']
                    SedarSpider['ukey'] = None
                    SedarSpider['update_date'] = datetime.now()
                    SedarSpider['domicile'] = df_row['DOMICILE']
                    SedarSpider['year'] = date.year
                    return SedarSpider.items
